# 代码要求

## 接口要求

对于视频处理类算法，由于现场可能存在输入多个视频流的问题，现在统一规定视频流处理输入接口为：

```json
{
    "args1": "算法自有参数1",
    "args2": "算法自有参数2",
    ......
    "cameraList":[
        {
            "id": "a111111",
            "index": "0",
            "url": "播放地址"
        },
        {
            "id": "a22222",
            "index": "1",
            "url": "播放地址"
        },
        {
            "id": "a33333",
            "index": "2",
            "url": "播放地址"
        },
        {
            .....
        }
    ],
    "plot": false
}
```

其中，输入包括算法自有参数，视频流列表以及是否展示参数，对于每个视频流，其包含摄像头id, index 以及 url。对于目标跟踪、人员计数等需要利用多个摄像头信息的算法，算法按照原有逻辑进行输出；对于指示灯检测、仪表识别等只需要单个摄像头信息的算法，json 格式的输出结果应该维护 `len(cameraList)` 个 json 文件，每个 json 文件名应该为 `{camera-id}.json`，json 文件里的结果仍为一个时间戳对应一个结果。

### 注意事项

* 由于参数列表存在 `list` 类型参数，视频流处理输入接口应该为 `POST` 类型。
* 对于多个视频流的输入，应使用 `threading` 库对多个视频流进行多线程并行处理，当收到停止处理请求时，将多个线程全部关闭。
* 时间戳获取参考代码：

```python
import os
import cv2

os.environ['OPENCV_FFMPEG_CAPTURE_OPTOINS']="keep_rtsp_timestamp;1"

cap = cv2.VideoCapture(url)
while True:
    ret, frame = cap.read()
    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)
    ......
```

* 经与基础服务确认，视频流中存在唯一的时间戳，但由于目前无法得到带有时间戳的视频流数据，上述代码无法测试准确性，存在未来修改的可能，目前只需要测试上述代码在处理自己输入的视频数据时是否可以正确读取时间戳，具体测试方法见 [自测要求](#自测要求)

## 展示要求

对于视频处理类算法，当设置 `plot=True` 时，经与李园华确认，输出图片路径及名称统一定为为 `/output/result.jpg`，即根目录下 `output` 文件夹下的 `result.jpg` 文件，且循环覆盖输出。

## 模型要求

* 确保模型初始化在 api 外面，不会每次调用重新初始化。
* 由于 `CUDA` 存在 `lazy init` 特性，表现为第一次调用算法较慢，之后调用算法速度正常，大家在封装 docker 时，在里面存一张推理图片，在初始化模型后进行一次推理操作再开启 flask 调用。

## 自测要求

* 对于视频处理类算法，要求对自己输入的视频自测无问题后再进行打包，自测通过 RTSP 流模拟器将准备的视频转化为流后输入到 docker 中进行测试，RTSP 流模拟器安装及使用教程可以参考 <https://www.easydarwin.org/tools/151.html>
